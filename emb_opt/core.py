# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_core.ipynb.

# %% auto 0
__all__ = ['build_batch_from_embeddings', 'Module', 'Executor', 'ProcessExecutor', 'ThreadExecutor', 'DatasetExecutor']

# %% ../nbs/02_core.ipynb 3
from .imports import *
from .utils import batch_list, unbatch_list
from .schemas import Batch, Embedding, Query

# %% ../nbs/02_core.ipynb 4
def build_batch_from_embeddings(embeddings: List[Embedding]):
    queries = []
    for i, embedding in enumerate(embeddings):
        query = Query(item=None, embedding=embedding, data=None, query_results=None)
        query.data['_internal']['collection_index'] = i
        queries.append(query)
        
    batch = Batch(queries=queries) 
    return batch

# %% ../nbs/02_core.ipynb 5
class Module():
    def __init__(self, 
                 output_schema: BaseModel,
                 function: Callable[List[BaseModel], List[BaseModel]], 
                ):
        self.output_schema = output_schema
        self.function = function
        
    def gather_inputs(self, batch: Batch) -> (List[Tuple], List[BaseModel]):
        raise NotImplementedError
        
    def validate_schema(self, results: List[BaseModel]) -> List[BaseModel]:
        results = [self.output_schema.model_validate(i) for i in results]
        return results
        
    def scatter_results(self, batch: Batch, idxs: List[Tuple], results: List[BaseModel]) -> None:
        raise NotImplementedError
        
    def __call__(self, batch: Batch) -> Batch:
        
        idxs, inputs = self.gather_inputs(batch)
        results = self.function(inputs)
        results = self.validate_schema(results)
        self.scatter_results(batch, idxs, results)
        return batch

# %% ../nbs/02_core.ipynb 6
class Executor():
    def __init__(self, 
                 function: Callable,
                 batched: bool,
                 batch_size: int=1
                ):
        self.function = function
        self.batched = batched
        self.batch_size = batch_size
    
    def batch_inputs(self, inputs: List[BaseModel]):
        if self.batched:
            inputs = batch_list(inputs, self.batch_size)
        return inputs
            
    def unbatch_inputs(self, results: List[BaseModel]):
        if self.batched:
            results = unbatch_list(results)
        return results

    def execute(self, inputs: List[BaseModel]):
        results = [self.function(i) for i in inputs]
        return results
        
    def __call__(self, inputs: List[BaseModel]) -> List[BaseModel]:
        
        inputs = self.batch_inputs(inputs)
        results = self.execute(inputs)
        results = self.unbatch_inputs(results)
            
        return results

# %% ../nbs/02_core.ipynb 7
class ProcessExecutor(Executor):
    def __init__(self,
                 function: Callable,
                 batched: bool,
                 batch_size: int=1,
                 concurrency: Optional[int]=1,
                ):
        
        self.function = function
        self.batched = batched
        self.concurrency = concurrency
        self.batch_size = batch_size
        
    def execute(self, inputs: List[BaseModel]):
        if (self.concurrency is None) or (self.concurrency==1):
            results = [self.function(i) for i in inputs]
        else:
            with ProcessPoolExecutor(min(self.concurrency, len(inputs))) as p:
                results = list(p.map(self.function, inputs))
            
        return results

# %% ../nbs/02_core.ipynb 8
class ThreadExecutor(Executor):
    def __init__(self,
                 function: Callable,
                 batched: bool,
                 batch_size: int=1,
                 concurrency: Optional[int]=1,
                ):
        
        self.function = function
        self.batched = batched
        self.concurrency = concurrency
        self.batch_size = batch_size
        
    def execute(self, inputs: List[BaseModel]):
        if (self.concurrency is None) or (self.concurrency==1):
            results = [self.function(i) for i in inputs]
        else:
            with ThreadPoolExecutor(min(self.concurrency, len(inputs))) as p:
                results = list(p.map(self.function, inputs))
            
        return results

# %% ../nbs/02_core.ipynb 9
class DatasetExecutor(Executor):
    def __init__(self,
                 function: Callable,
                 batched: bool,
                 batch_size: int=1,
                 concurrency: Optional[int]=1,
                 map_kwargs: Optional[dict]=None
                ):
        
        self.function = function
        self.batched = batched
        self.concurrency = concurrency
        self.batch_size = batch_size
        self.map_kwargs = map_kwargs if map_kwargs else {}
        
    def batch_inputs(self, inputs: List[BaseModel]):
        dataset = datasets.Dataset.from_list([i.model_dump() for i in inputs])
        return dataset
            
    def unbatch_inputs(self, dataset):
        return dataset.to_list()

    def execute(self, dataset):
        dataset = dataset.map(lambda row: self.function(row), batched=self.batched, 
                             batch_size=self.batch_size, num_proc=self.concurrency, **self.map_kwargs)
        return dataset
