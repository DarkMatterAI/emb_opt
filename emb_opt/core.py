# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_core.ipynb.

# %% auto 0
__all__ = ['QueryResult', 'dataset_from_query_results', 'Filter', 'PassThroughFilter', 'Score', 'VectorDatabase', 'GradQueryDB']

# %% ../nbs/01_core.ipynb 3
from .imports import *

# %% ../nbs/01_core.ipynb 5
class QueryResult():
    'Data model for emb_opt'
    def __init__(self, 
                 query_idx: int, # index of query vector
                 db_idx: int, # index of item in database
                 embedding: np.ndarray, # item embedding
                 distance: float, # distance to query vector
                 data: dict # any associated data
                ):
        self.query_idx = query_idx
        self.db_idx = db_idx
        self.embedding = embedding
        self.distance = distance
        self.data = data
        
    def to_dict(self) -> dict:
        return {
            'query_idx' : self.query_idx,
            'db_idx' : self.db_idx,
            'embedding' : self.embedding,
            'distance' : self.distance,
            'data' : self.data
        }

# %% ../nbs/01_core.ipynb 6
def dataset_from_query_results(query_results: list[QueryResult]) -> Dataset:
    'generates a `Dataset` from a list of `QueryResult`'
    data_dicts = [i.to_dict() for i in query_results]
    return Dataset.from_list(data_dicts)

# %% ../nbs/01_core.ipynb 9
class Filter():
    'Filter query results with `filter_func`'
    def __init__(self, 
                 filter_func: Callable, # function to filter
                 filter_kwargs_dict: Optional[dict]=None # optional kwargs dict passed to `Dataset.filter`
                ):
        self.filter_func = filter_func
        self.filter_kwargs_dict = filter_kwargs_dict if filter_kwargs_dict else {}
        
    def __call__(self, query_dataset: Dataset) -> Dataset:
        return query_dataset.filter(lambda item: self.filter_func(item), **self.filter_kwargs_dict)
    
class PassThroughFilter(Filter):
    'Dummy filter'
    def __init__(self):
        pass
    def __call__(self, query_dataset: Dataset) -> Dataset:
        return query_dataset

# %% ../nbs/01_core.ipynb 12
class Score():
    'Score query results with `score_func`'
    def __init__(self, 
                 score_func: Callable, # score function to maximize
                 map_kwargs_dict: Optional[dict]=None # optional kwargs for `Dataset.map`
                ):
        self.score_func = score_func
        self.map_kwargs_dict = map_kwargs_dict if map_kwargs_dict else {}
        
    def __call__(self, query_dataset: Dataset) -> Dataset:
        
        return query_dataset.map(lambda item: {'score' : self.score_func(item)}, **self.map_kwargs_dict)

# %% ../nbs/01_core.ipynb 15
class VectorDatabase():
    'Base class for vector database backends'
    def query(self, query_vectors: np.ndarray) -> Dataset:
        raise NotImplementedError

# %% ../nbs/01_core.ipynb 16
class GradQueryDB(VectorDatabase):
    '''
    GradQueryDB - uses a gradient provided by `grad_func` and 
    `grad_scales` to query along an arc defined by 
    `query[i,j] = query_vectors[i] - (grads[i]*grad_scales[j])`
    '''
    def __init__(self, 
                 vector_db: VectorDatabase, # Database to query
                 grad_func: Callable, # function to compute grads
                 grad_scales: np.ndarray # array of grad scales
                ):
        self.vector_db = vector_db
        self.grad_func = grad_func
        self.grad_scales = grad_scales
        
    def clean_results(self, query_results, query_idx):
        query_results = query_results.to_pandas()
        query_results = query_results.drop_duplicates(subset='db_idx')
        query_results['query_idx'] = query_idx
        query_results = query_results.reset_index(drop=True)
        query_results = datasets.Dataset.from_pandas(query_results)
        return query_results
        
    def query(self, query_vectors):
        
        grads = self.grad_func(query_vectors)
        query_batch = query_vectors[:,None] - (grads[:,None,:] * self.grad_scales[None,:,None])
        # (n,m,-1) = (n,1,-1) - ((n,1,-1) * (1,m,1))
        
        results = []
        
        for query_idx in range(query_vectors.shape[0]):
            q_iter = query_batch[query_idx]
            
            query_results = self.vector_db.query(q_iter)
            query_results = self.clean_results(query_results, query_idx)
            
            results += query_results.to_list()
            
        return datasets.Dataset.from_list(results) 
