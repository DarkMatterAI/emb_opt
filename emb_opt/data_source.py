# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/04_data_source.ipynb.

# %% auto 0
__all__ = ['DataSourceModule', 'DataSourcePlugin', 'NumpyDataPlugin', 'DataPluginGradWrapper']

# %% ../nbs/04_data_source.ipynb 3
from .imports import *
from .utils import build_batch_from_embeddings
from .module import Module
from .schemas import Item, Query, Batch, DataSourceFunction, DataSourceResponse

# %% ../nbs/04_data_source.ipynb 5
class DataSourceModule(Module):
    def __init__(self, 
                 function: DataSourceFunction # data function
                ):
        super().__init__(DataSourceResponse, function)
        
    def gather_inputs(self, batch: Batch) -> (List[Tuple], List[Query]):
        idxs, inputs = batch.flatten_queries()
        return (idxs, inputs)
    
    def scatter_results(self, batch: Batch, idxs: List[Tuple], results: List[DataSourceResponse]):
        for (q_idx, r_idx), result in zip(idxs, results):
            batch_item = batch.get_item(q_idx, r_idx)
            if result.data:
                batch_item.data.update(result.data)
                
            if not result.valid:
                batch_item.update_internal(removed=True, removal_reason='invalid query')
                
            elif len(result.query_results)==0:
                batch_item.update_internal(removed=True, removal_reason='query returned no results')
                
            else:
                batch_item.add_query_results(result.query_results)

# %% ../nbs/04_data_source.ipynb 9
class DataSourcePlugin():
    '''
    DataSourcePlugin - documentation for plugin functions to `DataSourceFunction`
    
    A valid `DataSourceFunction` is any function that maps `List[Query]` to 
    `List[DataSourceResponse]`. The inputs will be given as `Query` objects. 
    The outputs can be either a list of `DataSourceResponse` objects or a list of 
    valid json dictionaries that match the `DataSourceResponse` schema
    
    Query schema:
    
    `{
        'item' : Optional[Any],
        'embedding' : List[float],
        'data' : Optional[Dict],
        'query_results': [] # will be empty at this stage
    }`
    
    Item schema:
    
    `{
        'id' : Optional[Union[str, int]]
        'item' : Optional[Any],
        'embedding' : List[float],
        'score' : None, # will be None at this stage
        'data' : Optional[Dict],
    }`
    
    Input schema:
    
    `List[Query]`
    
    DataSourceResponse schema:
    
    `{
        'valid' : bool,
        'data' : Optional[Dict],
        'query_results' : List[Item]
    }`
    
    Output schema:
    
    `List[DataSourceResponse]`
    
    '''
    def __call__(self, inputs: List[Query]) -> List[DataSourceResponse]:
        pass

# %% ../nbs/04_data_source.ipynb 11
class NumpyDataPlugin(DataSourcePlugin):
    '''
    NumpyDataPlugin - data plugin for working with numpy arrays. The 
    data query will run `k` nearest neighbors of the query embeddings 
    against the `item_embeddings` using `distance_metric`
    
    Optionally, `item_data` can be provided as a list of dicts, where 
    `item_data[i]` corresponds to the data for `item_embeddings[i]`.
    
    If `item_data` is provided, `item_data[i]['id_key']` defines 
    the ID of item `i`, and `item_data[i]['item_key']` defines the 
    specific item `i`
    
    `distance_metric` is any valid scipy distance metric. see 
    https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html
    
    if `distance_cutoff` is specified, query results with a distance 
    greater than `distance_cutoff` are ignored
    '''
    def __init__(self,
                 k: int,                               # k nearest neighbors to return
                 item_embeddings: np.ndarray,          # item embeddings
                 item_data: Optional[List[Dict]]=None, # Optional dict of item data
                 id_key: Optional[str]=None,           # Optional key for item id (should be in `item_data` dict)
                 item_key: Optional[str]=None,         # Optional key for item value (should be in `item_data` dict)
                 distance_metric: str='euclidean',     # distance metric, see options at https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html
                 distance_cutoff: Optional[float]=None # query to result distance cutoff
                ):
        
        self.k = k
        self.item_embeddings = item_embeddings
        self.item_data = item_data
        self.id_key = id_key
        self.item_key = item_key
        self.distance_metric = distance_metric
        self.distance_cutoff = distance_cutoff if distance_cutoff is not None else float('inf')
        
    def get_data(self, idx):
        data = None
        item_value = None
        item_id = None
        
        if self.item_data:
            data = dict(self.item_data[idx])
            if self.id_key:
                item_id = data.pop(self.id_key)
                
            if self.item_key:
                item_value = data.pop(self.item_key)
                
        return data, item_value, item_id
        
    def __call__(self, inputs: List[Query]) -> List[DataSourceResponse]:
        
        queries = np.array([i.embedding for i in inputs])
        distances = cdist(queries, self.item_embeddings, metric=self.distance_metric)
        topk = distances.argsort(-1)[:, :self.k]
        
        outputs = []
        for i in range(len(inputs)):
            items = []
            query_data = {'query_distance' : []}
            for j in topk[i]:
                distance = distances[i,j]
                if distance < self.distance_cutoff:
                    query_data['query_distance'].append(distances[i,j])
                    
                    data, item_value, item_id = self.get_data(j)

                    item = Item(id=item_id, 
                                item=item_value,
                                embedding=self.item_embeddings[j], 
                                data=data, 
                                score=None)
                    items.append(item)
                
            result = DataSourceResponse(valid=bool(items), data=query_data, query_results=items)
            outputs.append(result)
            
        return outputs

# %% ../nbs/04_data_source.ipynb 13
class DataPluginGradWrapper():
    '''
    DataPluginGradWrapper - wraps a `DataSourceFunction` to allow for 
    gradient-based queries. The score gradient is used to generate 
    hypothetical query embeddings following `new_query = old_query + lr*grad`
    
    This should be used in conjunction with `UpdatePluginGradientWrapper` or 
    an `UpdateFunction` that assigns the gradient to `query.data['_score_grad']`  
    
    Note that the gradient in this case is expected to point in the direction of 
    _increasing_ score. If using a custom gradient computation method, you may 
    need to flip the sign of the gradient
    '''
    def __init__(self, 
                 function: DataSourceFunction, # data function to wrap
                 lrs: np.ndarray               # array of learning rates
                ):
        self.function = function
        self.lrs = np.array(lrs)
        self.output_schema = DataSourceResponse
        
    def validate_schema(self, results: List[BaseModel]) -> List[BaseModel]:
        results = [self.output_schema.model_validate(i) for i in results]
        return results
        
    def gather_inputs(self, inputs: List[Query]) -> (List[Tuple], List[Query]):
        new_inputs = []
        idxs = []
        
        for query_idx, query in enumerate(inputs):
            new_queries = []
            
            query_embedding = np.array(query.embedding)
            new_queries.append(query_embedding)
            
            grad = query.data.get('_score_grad', None)
            if grad is not None:
                grad_queries = query_embedding[None,:] + (grad[None,:]*self.lrs[:,None])
                
                for new_query in grad_queries:
                    new_queries.append(new_query)
                    
            new_inputs += new_queries
            idxs += [query_idx for i in new_queries]
            
        new_inputs = [Query.from_minimal(embedding=i) for i in new_inputs]
        return idxs, new_inputs
    
    def scatter_results(self, 
                        inputs: List[Query], 
                        idxs: List[Tuple], 
                        results: List[DataSourceResponse]
                       ) -> List[DataSourceResponse]:
        
        outputs = [DataSourceResponse(valid=True, data={'subquery_data':[]}, query_results=[]) 
                   for i in inputs]
        
        for i, result in enumerate(results):
            if result.valid:
                input_idx = idxs[i]
                outputs[input_idx].data['subquery_data'].append(result.data)
                outputs[input_idx].query_results += result.query_results
                
        for output in outputs:
            unique_results = {i.id : i for i in output.query_results}
            output.query_results = list(unique_results.values())
            
        return outputs
        
    def __call__(self, inputs: List[Query]) -> List[DataSourceResponse]:
        
        idxs, new_inputs = self.gather_inputs(inputs)
        results = self.function(new_inputs)
        results = self.validate_schema(results)
        outputs = self.scatter_results(inputs, idxs, results)
        return outputs

