{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# runner\n",
    "\n",
    "> runner functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from emb_opt.imports import *\n",
    "from emb_opt.utils import pack_dataset\n",
    "from emb_opt.core import VectorDatabase, Score, Filter, PassThroughFilter\n",
    "from emb_opt.query_update import QueryUpdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SearchLog():\n",
    "    'Logs results from `Runner`'\n",
    "    def __init__(self):\n",
    "        self.batch_log = {}\n",
    "        \n",
    "    def add_entry(self, \n",
    "                  iteration: int, \n",
    "                  query_vectors: np.ndarray, \n",
    "                  query_results: Dataset\n",
    "                 ):\n",
    "        self.batch_log[iteration] = {'queries' : query_vectors, 'results' : query_results}\n",
    "        \n",
    "    def compile_results(self) -> Dataset:\n",
    "        results = []\n",
    "        seen_keys = set()\n",
    "\n",
    "        for k,v in self.batch_log.items():\n",
    "            query_results = v['results']\n",
    "\n",
    "            for row in query_results.to_list():\n",
    "                if not (row['db_idx'] in seen_keys):\n",
    "                    row.pop('query_idx')\n",
    "                    row.pop('distance')\n",
    "                    results.append(row)\n",
    "                    seen_keys.update({row['db_idx']})\n",
    "\n",
    "        return Dataset.from_list(results)\n",
    "    \n",
    "    def compile_trajectories(self) -> dict:\n",
    "        \n",
    "        n_queries = self.batch_log[0]['queries'].shape[0]\n",
    "        n_iters = len(self.batch_log.keys())\n",
    "        trajectories = {i:{'query_vectors':[], 'scores':[]} for i in range(n_queries)}\n",
    "        \n",
    "        for iteration in range(n_iters):\n",
    "            queries = self.batch_log[iteration]['queries']\n",
    "            score_dict = pack_dataset(self.batch_log[iteration]['results'], 'query_idx', ['score'])\n",
    "            \n",
    "            for query_idx in range(n_queries):\n",
    "                trajectories[query_idx]['query_vectors'].append(queries[query_idx])\n",
    "                trajectories[query_idx]['scores'].append(score_dict[query_idx]['score'])\n",
    "\n",
    "        for query_idx in range(n_queries):\n",
    "            trajectories[query_idx]['query_vectors'] = np.stack(trajectories[query_idx]['query_vectors'])\n",
    "            \n",
    "        return trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runner\n",
    "\n",
    "The `Runner` class combines a `VectorDatabase`, a `Score`, a `QueryUpdate` and a `Filter` to search a vector database for high scoring items. The search loop:\n",
    "\n",
    "* 1. Start with `query_vectors`\n",
    "* 2. Query `VectorDatabase` with `query_vectors` to get `query_results`\n",
    "* 3. Filter `query_results` with `Filter`\n",
    "* 4. Score `query_results` with `Score`\n",
    "* 5. Use `QueryUpdate` to generate a new set of `query_vectors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Runner():\n",
    "    'Runs embedding optimization search'\n",
    "    def __init__(self, \n",
    "                 vector_db: VectorDatabase, # vector database backend\n",
    "                 score: Score, # score function\n",
    "                 query_update: QueryUpdate, # query update\n",
    "                 filter: Optional[Filter]=None # optional filter\n",
    "                ):\n",
    "        \n",
    "        self.vector_db = vector_db\n",
    "        self.score = score\n",
    "        self.query_update = query_update\n",
    "        self.filter = filter if filter else PassThroughFilter()\n",
    "        \n",
    "    def search(self, \n",
    "               query_vectors: np.ndarray, \n",
    "               iterations: int\n",
    "              ) -> SearchLog:\n",
    "        log = SearchLog()\n",
    "        \n",
    "        for i in range(iterations):\n",
    "            query_results = self.vector_db.query(query_vectors)\n",
    "            query_results = self.filter(query_results)\n",
    "            query_results = self.score(query_results)\n",
    "            \n",
    "            log.add_entry(i, query_vectors, query_results)\n",
    "            \n",
    "            query_vectors = self.query_update(query_vectors, query_results)\n",
    "            \n",
    "        return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emb_opt",
   "language": "python",
   "name": "emb_opt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
