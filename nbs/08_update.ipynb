{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update\n",
    "\n",
    "> Update functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from emb_opt.imports import *\n",
    "from emb_opt.utils import compute_rl_grad, query_to_rl_inputs\n",
    "from emb_opt.module import Module\n",
    "from emb_opt.schemas import Item, Query, Batch, UpdateFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Update step uses a set of queries and scored results to generate a new set of queries for the next iteration of the search.\n",
    "\n",
    "Updates are denoted as `discrete` or `continuous`. `continuous` updates generate new query embeddings purely in embedding space (ie by averaging several embeddings). As a result, `continuous` update outputs do not have a specific `item` associated with them. `discrete` updates use a specific query result `Item` as the update, maintaining the `item` associated with it.\n",
    "\n",
    "The update step is formalized by the `UpdateFunction` schema, which maps inputs `List[Query]` to outputs `List[Query]`. Note that the number of outputs can be different from the number of inputs.\n",
    "\n",
    "The `UpdateModule` manages execution of a `UpdateFunction`. The `UpdateModule` gathers valid items, sends them to the `UpdateFunction`, and processes the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class UpdateModule(Module):\n",
    "    def __init__(self, function: UpdateFunction):\n",
    "        super().__init__(Query, function)\n",
    "        \n",
    "    def gather_inputs(self, batch: Batch) -> (List[Tuple], List[Query]):\n",
    "        idxs, inputs = batch.flatten_queries()\n",
    "        return (idxs, inputs)\n",
    "    \n",
    "    def __call__(self, batch: Batch) -> Batch:\n",
    "        \n",
    "        idxs, inputs = self.gather_inputs(batch)\n",
    "        new_queries = self.function(inputs)\n",
    "        new_queries = self.validate_schema(new_queries)\n",
    "        return Batch(queries=new_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def passthrough_update_test(queries):\n",
    "    return queries\n",
    "\n",
    "batch = Batch(queries=[\n",
    "                        Query.from_minimal(embedding=[0.1]),\n",
    "                        Query.from_minimal(embedding=[0.2]),\n",
    "                        Query.from_minimal(embedding=[0.3]),\n",
    "                    ])\n",
    "\n",
    "update_module = UpdateModule(passthrough_update_test)\n",
    "\n",
    "batch = update_module(batch)\n",
    "\n",
    "assert isinstance(batch, Batch)\n",
    "assert isinstance(batch[0], Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous_update_test(queries):\n",
    "    outputs = []\n",
    "    for query in queries:\n",
    "        new_query = Query.from_parent_query(embedding=[i*2 for i in query.embedding], parent_query=query)\n",
    "        outputs.append(new_query)\n",
    "    return outputs\n",
    "\n",
    "batch = Batch(queries=[\n",
    "                        Query.from_minimal(embedding=[0.1]),\n",
    "                        Query.from_minimal(embedding=[0.2]),\n",
    "                        Query.from_minimal(embedding=[0.3]),\n",
    "                    ])\n",
    "\n",
    "[batch.queries[i].update_internal(collection_id=i) for i in range(len(batch))]\n",
    "\n",
    "update_module = UpdateModule(continuous_update_test)\n",
    "\n",
    "batch2 = update_module(batch)\n",
    "\n",
    "assert all([batch2[i].internal.collection_id==batch[i].internal.collection_id for i in range(len(batch2))])\n",
    "\n",
    "assert isinstance(batch2, Batch)\n",
    "assert isinstance(batch2[0], Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_update_test(queries):\n",
    "    return [Query.from_item(i[0]) for i in queries]\n",
    "\n",
    "queries = []\n",
    "for i in range(3):\n",
    "    q = Query.from_minimal(embedding=[i*0.1])\n",
    "    q.update_internal(collection_id=i)\n",
    "    r = Item.from_minimal(embedding=[i*2*0.1])\n",
    "    q.add_query_results([r])\n",
    "    queries.append(q)\n",
    "    \n",
    "batch = Batch(queries=queries)\n",
    "\n",
    "update_module = UpdateModule(discrete_update_test)\n",
    "\n",
    "batch2 = update_module(batch)\n",
    "\n",
    "assert isinstance(batch2, Batch)\n",
    "assert isinstance(batch2[0], Query)\n",
    "\n",
    "for i in range(len(batch2)):\n",
    "    assert batch2[i].internal.parent_id == batch[i][0].internal.parent_id\n",
    "    assert batch2[i].data['_source_item_id'] == batch[i][0].id\n",
    "    assert batch2[i].internal.collection_id == batch[i].internal.collection_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class UpdatePlugin():\n",
    "    '''\n",
    "    UpdatePlugin - documentation for plugin functions to `UpdateFunction`\n",
    "    \n",
    "    A valid `UpdateFunction` is any function that maps `List[Query]` to \n",
    "    `List[Query]`. The inputs will be given as `Query` objects. \n",
    "    The outputs can be either a list of `Query` objects or a list of \n",
    "    valid json dictionaries that match the `Query` schema. The number of \n",
    "    outputs can be different from the number of inputs\n",
    "    \n",
    "    Item schema:\n",
    "    \n",
    "    `{\n",
    "        'id' : Optional[Union[str, int]]\n",
    "        'item' : Optional[Any],\n",
    "        'embedding' : List[float],\n",
    "        'score' : float,\n",
    "        'data' : Optional[Dict],\n",
    "    }`\n",
    "    \n",
    "    \n",
    "    Query schema:\n",
    "    \n",
    "    `{\n",
    "        'item' : Optional[Any],\n",
    "        'embedding' : List[float],\n",
    "        'data' : Optional[Dict],\n",
    "        'query_results': List[Item]\n",
    "    }`\n",
    "    \n",
    "    Input schema:\n",
    "    \n",
    "    `List[Query]`\n",
    "\n",
    "    Output schema:\n",
    "    \n",
    "    `List[Query]`\n",
    "    \n",
    "    '''\n",
    "    def __call__(self, inputs: List[Query]) -> List[Query]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class UpdatePluginGradientWrapper():\n",
    "    '''\n",
    "    UpdatePluginGradientWrapper - this class wraps a valid \n",
    "    `UpdateFunction` to estimate the gradient of new queries \n",
    "    using the results and scores computed for the parent query.\n",
    "    \n",
    "    This wrapper integrates with `DataPluginGradWrapper`, which \n",
    "    allows us to create new query vectors based on the gradient\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 function: UpdateFunction,                          # `UpdateFunction` to wrap\n",
    "                 distance_penalty: float=0,                         # RL grad distance penalty\n",
    "                 max_norm: Optional[float] = None,                  # max grad norm\n",
    "                 norm_type: Optional[Union[float, int, str]] = 2.0  # grad norm type\n",
    "                ):\n",
    "        \n",
    "        self.function = function\n",
    "        self.distance_penalty = distance_penalty\n",
    "        self.max_norm = max_norm\n",
    "        self.norm_type = norm_type\n",
    "        \n",
    "    def __call__(self, inputs: List[Query]) -> List[Query]:\n",
    "        outputs = self.function(inputs)\n",
    "        \n",
    "        id_dict = {i.id : i for i in inputs}\n",
    "        \n",
    "        for query in outputs:\n",
    "            parent = id_dict.get(query.internal.parent_id, None)\n",
    "            if parent:\n",
    "                _, result_embeddings, scores = query_to_rl_inputs(parent)\n",
    "                query_embedding = np.array(query.embedding)\n",
    "                grad = compute_rl_grad(query_embedding, \n",
    "                                       result_embeddings, \n",
    "                                       scores,\n",
    "                                       distance_penalty=self.distance_penalty,\n",
    "                                       max_norm=self.max_norm, \n",
    "                                       norm_type=self.norm_type,\n",
    "                                       score_grad=True\n",
    "                                      )\n",
    "            else:\n",
    "                grad = np.zeros(np.array(query.embedding).shape)\n",
    "                \n",
    "            query.data['_score_grad'] = grad\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class TopKDiscreteUpdate(UpdatePlugin):\n",
    "    '''\n",
    "    TopKDiscreteUpdate - discrete update that \n",
    "    generates `k` new queries from the top `k` \n",
    "    scoring items in each input query\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 k: int # top k items to return as new queries\n",
    "                ):\n",
    "        self.k = k\n",
    "        \n",
    "    def __call__(self, inputs: List[Query]) -> List[Query]:\n",
    "        outputs = []\n",
    "        \n",
    "        for query in inputs:\n",
    "            result_scores = np.array([i.score for i in query.valid_results()])\n",
    "            topk_idxs = result_scores.argsort()[::-1][:self.k]\n",
    "            top_items = [query[i] for i in topk_idxs]\n",
    "            outputs += top_items\n",
    "            \n",
    "        outputs = [Query.from_item(i) for i in outputs]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = Query.from_minimal(embedding=[0.1])\n",
    "q1.add_query_results([\n",
    "    Item(id=None, item='1', embedding=[0.11], score=-10, data=None),\n",
    "    Item(id=None, item='2', embedding=[0.12], score=6, data=None),\n",
    "    Item(id=None, item='3', embedding=[0.12], score=1, data=None),\n",
    "])\n",
    "\n",
    "q2 = Query.from_minimal(embedding=[0.2])\n",
    "q2.add_query_results([\n",
    "    Item(id=None, item='4', embedding=[0.21], score=4, data=None),\n",
    "    Item(id=None, item='5', embedding=[0.22], score=5, data=None),\n",
    "    Item(id=None, item='6', embedding=[0.12], score=2, data=None),\n",
    "])\n",
    "\n",
    "batch = Batch(queries=[q1, q2])\n",
    "\n",
    "update_func = TopKDiscreteUpdate(k=2)\n",
    "update_module = UpdateModule(update_func)\n",
    "batch2 = update_module(batch)\n",
    "\n",
    "assert [i.item for i in batch2] == ['2', '3', '5', '4']\n",
    "\n",
    "update_func2 = UpdatePluginGradientWrapper(update_func)\n",
    "update_module2 = UpdateModule(update_func2)\n",
    "batch3 = update_module2(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class TopKContinuousUpdate():\n",
    "    '''\n",
    "    TopKContinuousUpdate - continuous update that \n",
    "    generates 1 new query by averaging the top `k` \n",
    "    scoring item embeddings for each input query\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 k: int # top k items to average\n",
    "                ):\n",
    "        self.k = k\n",
    "        \n",
    "    def __call__(self, inputs: List[Query]) -> List[Query]:\n",
    "        outputs = []\n",
    "        \n",
    "        for query in inputs:\n",
    "            result_scores = np.array([i.score for i in query.valid_results()])\n",
    "            topk_idxs = result_scores.argsort()[::-1][:self.k]\n",
    "            topk_embs = np.array([query[i].embedding for i in topk_idxs])\n",
    "            \n",
    "            new_embedding = np.average(topk_embs, 0)\n",
    "            output = Query.from_parent_query(embedding=new_embedding, parent_query=query)\n",
    "            outputs.append(output)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = Query.from_minimal(embedding=[0.1])\n",
    "q1.add_query_results([\n",
    "    Item(id=None, item='1', embedding=[0.1], score=-10, data=None),\n",
    "    Item(id=None, item='2', embedding=[0.2], score=6, data=None),\n",
    "])\n",
    "\n",
    "q2 = Query.from_minimal(embedding=[0.2])\n",
    "q2.add_query_results([\n",
    "    Item(id=None, item='4', embedding=[0.2], score=4, data=None),\n",
    "    Item(id=None, item='5', embedding=[0.3], score=5, data=None),\n",
    "])\n",
    "\n",
    "batch = Batch(queries=[q1, q2])\n",
    "\n",
    "update_func = TopKContinuousUpdate(k=2)\n",
    "update_module = UpdateModule(update_func)\n",
    "batch2 = update_module(batch)\n",
    "\n",
    "assert np.allclose([i.embedding for i in batch2], [[0.15], [0.25]])\n",
    "\n",
    "update_func = TopKContinuousUpdate(k=1)\n",
    "update_module = UpdateModule(update_func)\n",
    "batch2 = update_module(batch)\n",
    "\n",
    "assert np.allclose([i.embedding for i in batch2], [[0.2], [0.3]])\n",
    "\n",
    "update_func2 = UpdatePluginGradientWrapper(update_func)\n",
    "update_module2 = UpdateModule(update_func2)\n",
    "batch3 = update_module2(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class RLUpdate():\n",
    "    '''\n",
    "    RLUpdate - uses reinforcement learning to update queries\n",
    "    \n",
    "    To compute the gradient with RL:\n",
    "    1. compute advantages by whitening scores\n",
    "        1. `advantage[i] = (scores[i] - scores.mean()) / scores.std()`\n",
    "    2. compute advantage loss\n",
    "        1. `advantage_loss[i] = advantage[i] * (query_embedding - result_embedding[i])**2`\n",
    "    3. compute distance loss\n",
    "        1. `distance_loss[i] = distance_penalty * (query_embedding - result_embedding[i])**2`\n",
    "    4. sum loss terms\n",
    "        1. `loss[i] = advantage_loss[i] + distance_loss[i]`\n",
    "    5. compute the gradient\n",
    "    \n",
    "    This gives a closed for calculation of the gradient as:\n",
    "    \n",
    "    `grad[i] = 2 * (advantage[i] + distance_penalty) * (query_embedding - result_embedding[i])`    \n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 lrs: Union[List[float], np.ndarray],            # list of learning rates\n",
    "                 distance_penalty: float,                        # distance penalty coefficient\n",
    "                 max_norm: Optional[float]=None,                 # optional max grad norm for clipping\n",
    "                 norm_type: Optional[Union[float, int, str]]=2.0 # norm type\n",
    "                ):\n",
    "        self.lrs = np.array(lrs)\n",
    "        self.distance_penalty = distance_penalty\n",
    "        self.max_norm = max_norm\n",
    "        self.norm_type = norm_type\n",
    "        \n",
    "    def compute_grad(self, query: Query):\n",
    "        query_embedding, result_embeddings, scores = query_to_rl_inputs(query)\n",
    "        \n",
    "        grad = compute_rl_grad(query_embedding, result_embeddings, scores, \n",
    "                               self.distance_penalty, self.max_norm, self.norm_type)\n",
    "        \n",
    "        return grad\n",
    "        \n",
    "    def __call__(self, queries: List[Query]) -> List[Query]:\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for query in queries:\n",
    "            grad = self.compute_grad(query)\n",
    "            query_embedding = np.array(query.embedding)\n",
    "            new_embeddings = query_embedding[None] - (grad[None] * self.lrs[:,None])  # (1,n) - (1,n) * (k,1)\n",
    "            \n",
    "            for i in range(new_embeddings.shape[0]):\n",
    "                assert new_embeddings[i].shape == query_embedding.shape\n",
    "                \n",
    "                new_query = Query.from_parent_query(embedding=new_embeddings[i].tolist(), \n",
    "                                                    parent_query=query)\n",
    "                \n",
    "                new_query.data['rl_update_details'] = {\n",
    "                                                        'parent_embedding' : query_embedding.tolist(),\n",
    "                                                        'lr' : self.lrs[i],\n",
    "                                                        'grad' : grad.tolist(),\n",
    "                                                    }\n",
    "                \n",
    "                results.append(new_query)\n",
    "                \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = np.array([1e-2, 1e-1, 1e0, 1e1])\n",
    "dp = 0.1\n",
    "\n",
    "update_function = RLUpdate(lrs, dp, max_norm=1.)\n",
    "\n",
    "update_module = UpdateModule(update_function)\n",
    "\n",
    "queries = []\n",
    "for i in range(1,4):\n",
    "    q = Query.from_minimal(embedding=[i*0.1, i*0.2, i*0.3, 0.1, 0.1])\n",
    "    q.update_internal(collection_id=i)\n",
    "    r1 = Item.from_minimal(embedding=[2*i*0.1, 2*i*0.2, 2*i*0.3, -0.1, -0.1], score=i*1.5)\n",
    "    r2 = Item.from_minimal(embedding=[-2*i*0.1, 2*i*0.2, -2*i*0.3, -0.1, -0.1], score=i*.5)\n",
    "    q.add_query_results([r1, r2])\n",
    "    queries.append(q)\n",
    "    \n",
    "batch = Batch(queries=queries)\n",
    "\n",
    "batch2 = update_module(batch)\n",
    "\n",
    "assert len(batch2)/len(batch) == len(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emb_opt",
   "language": "python",
   "name": "emb_opt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
