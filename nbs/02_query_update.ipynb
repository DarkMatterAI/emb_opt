{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# query update\n",
    "\n",
    "> query update functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp query_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmai/miniconda3/envs/emb_opt/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from emb_opt.imports import *\n",
    "from emb_opt.utils import pack_dataset, whiten\n",
    "from emb_opt.backends.hf import HFDatabase\n",
    "from emb_opt.core import Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Update\n",
    "\n",
    "The role of `QueryUpdate` is to take a set of `query_vectors`, a scored `query_dataset` and generate a new set of `query_vectors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class QueryUpdate():\n",
    "    'Query update base class'\n",
    "    def __call__(self, \n",
    "                 query_vectors: np.ndarray, # query vectors\n",
    "                 query_dataset: Dataset # scored dataset\n",
    "                ) -> np.ndarray: # new query vectors\n",
    "        return query_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning\n",
    "\n",
    "`RLUpdate` uses basic reinforcement learning to update query vectors. For each query, we gather the `embedding` and `score` of each item returned. We `whiten` the scores so that above average scores have a positive value and below average scores have a negative value. Our gradient update tells the query vectory to move closer to positive value scores and further from negative value scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class RLUpdate(QueryUpdate):\n",
    "    'Reinforcement Learning update'\n",
    "    def __init__(self, \n",
    "                 lr: float # learning rate\n",
    "                ):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def __call__(self, \n",
    "                 query_vectors: np.ndarray, # query vectors\n",
    "                 query_dataset: Dataset # scored dataset\n",
    "                ) -> np.ndarray: # new query vectors\n",
    "        \n",
    "        packed_dict = pack_dataset(query_dataset, 'query_idx', ['embedding', 'score'])\n",
    "        grads = []\n",
    "        \n",
    "        for query_idx in range(query_vectors.shape[0]):\n",
    "            embs = np.array(packed_dict[query_idx]['embedding'])\n",
    "            scores = np.array(packed_dict[query_idx]['score'])\n",
    "\n",
    "            advantages = whiten(scores)\n",
    "            grad = (advantages[:,None] * (2*(query_vectors[query_idx][None] - embs))).mean(0)\n",
    "            grads.append(grad)\n",
    "\n",
    "        grads = np.array(grads)\n",
    "        updated_query_vectors = query_vectors - self.lr*grads\n",
    "        return updated_query_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 1813.36it/s]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def dummy_score(row):\n",
    "    return np.linalg.norm(row['embedding'])\n",
    "\n",
    "vectors = np.random.randn(128, 256)\n",
    "vector_dataset = Dataset.from_list([{'embedding' : i} for i in vectors])\n",
    "vector_dataset.add_faiss_index('embedding')\n",
    "\n",
    "db = HFDatabase(vector_dataset, 'embedding', 10)\n",
    "score = Score(dummy_score)\n",
    "update_strategy = RLUpdate(0.5)\n",
    "\n",
    "\n",
    "query_vectors = np.random.randn(3, 256)/10\n",
    "query_dataset = db.query(query_vectors)\n",
    "query_dataset = score(query_dataset)\n",
    "updated_queries = update_strategy(query_vectors, query_dataset)\n",
    "\n",
    "assert np.all(np.linalg.norm(updated_queries, axis=-1) > np.linalg.norm(query_vectors, axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top K\n",
    "\n",
    "`TopKUpdate` creates a new `query_vector` from the top `k` results returned. If `score_weighting=True`, a score-weighted average is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class TopKUpdate(QueryUpdate):\n",
    "    'Top K update'\n",
    "    def __init__(self, \n",
    "                 k: int, # top k value\n",
    "                 score_weighting: bool=True # if True, top k average is weighted by score\n",
    "                ):\n",
    "        self.k = k\n",
    "        self.score_weighting = score_weighting\n",
    "        \n",
    "    def __call__(self, \n",
    "                 query_vectors: np.ndarray, # query vectors\n",
    "                 query_dataset: Dataset # scored dataset\n",
    "                ) -> np.ndarray: # new query vectors\n",
    "        \n",
    "        packed_dict = pack_dataset(query_dataset, 'query_idx', ['embedding', 'score'])\n",
    "        new_queries = []\n",
    "        \n",
    "        for query_idx in range(query_vectors.shape[0]):\n",
    "            embs = np.array(packed_dict[query_idx]['embedding'])\n",
    "            scores = np.array(packed_dict[query_idx]['score'])\n",
    "\n",
    "            topk_idxs = scores.argsort()[::-1][:self.k]\n",
    "            topk_embs = embs[topk_idxs]\n",
    "            topk_scores = scores[topk_idxs]\n",
    "\n",
    "            if self.score_weighting:\n",
    "                new_queries.append(np.average(topk_embs, 0, weights=topk_scores))\n",
    "            else:\n",
    "                new_queries.append(np.average(topk_embs, 0))\n",
    "\n",
    "        query_vectors = np.array(new_queries)\n",
    "        \n",
    "        return query_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 1978.45it/s]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def dummy_score(row):\n",
    "    return np.linalg.norm(row['embedding'])\n",
    "\n",
    "vectors = np.random.randn(128, 256)\n",
    "vector_dataset = Dataset.from_list([{'embedding' : i} for i in vectors])\n",
    "vector_dataset.add_faiss_index('embedding')\n",
    "\n",
    "db = HFDatabase(vector_dataset, 'embedding', 10)\n",
    "score = Score(dummy_score)\n",
    "update_strategy = TopKUpdate(3)\n",
    "\n",
    "\n",
    "query_vectors = np.random.randn(3, 256)/10\n",
    "query_dataset = db.query(query_vectors)\n",
    "query_dataset = score(query_dataset)\n",
    "updated_queries = update_strategy(query_vectors, query_dataset)\n",
    "\n",
    "assert np.all(np.linalg.norm(updated_queries, axis=-1) > np.linalg.norm(query_vectors, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emb_opt",
   "language": "python",
   "name": "emb_opt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
