{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune\n",
    "\n",
    "> Prune functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmai/miniconda3/envs/emb_opt/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from emb_opt.imports import *\n",
    "from emb_opt.core import Module\n",
    "from emb_opt.schemas import Item, Query, Batch, PruneFunction, PruneResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class PruneModule(Module):\n",
    "    def __init__(self,\n",
    "                 function: PruneFunction,\n",
    "                ):\n",
    "        super().__init__(PruneResponse, function)\n",
    "        \n",
    "    def gather_inputs(self, batch: Batch) -> (List[Tuple], List[Query]):\n",
    "        idxs, inputs = batch.flatten_queries()\n",
    "        return (idxs, inputs)\n",
    "    \n",
    "    def scatter_results(self, batch: Batch, idxs: List[Tuple], results: List[PruneResponse]):\n",
    "        for (q_idx, r_idx), result in zip(idxs, results):\n",
    "            batch_item = batch.get_item(q_idx, r_idx)\n",
    "            if result.data:\n",
    "                batch_item.data.update(result.data)\n",
    "\n",
    "            if not result.valid:\n",
    "                batch_item.data['_internal']['remove'] = True\n",
    "                batch_item.data['_internal']['remove_details'] = 'prune result invalid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Batch(queries=[\n",
    "                        Query(embedding=[0.1]),\n",
    "                        Query(embedding=[0.2]),\n",
    "                        Query(embedding=[0.3]),\n",
    "                    ])\n",
    "\n",
    "def prune_func(queries):\n",
    "    return [PruneResponse(valid=i.embedding[0]>=0.2) for i in queries]\n",
    "\n",
    "prune_module = PruneModule(prune_func)\n",
    "\n",
    "batch = prune_module(batch)\n",
    "assert [i.data['_internal'].get('remove', False) for i in batch] == [True, False, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class TopKPrune():\n",
    "    def __init__(self,\n",
    "                 k: int,\n",
    "                 agg: str='mean',\n",
    "                 local: bool=True\n",
    "                ):\n",
    "        self.k = k\n",
    "        self.agg = agg\n",
    "        self.local = local\n",
    "        assert agg in ['mean', 'max']\n",
    "        \n",
    "    def prune_queries(self, queries: List[Query]) -> List[PruneResponse]:\n",
    "        scores = [np.array([j.score for j in i]) for i in queries]\n",
    "        \n",
    "        if self.agg=='mean':\n",
    "            scores = np.array([i.mean() for i in scores])\n",
    "        elif self.agg=='max':\n",
    "            scores = np.array([i.max() for i in scores])\n",
    "            \n",
    "        topk_idxs = set(scores.argsort()[::-1][:self.k])\n",
    "        \n",
    "        outputs = [PruneResponse(valid=(i in topk_idxs), data={f'{self.agg}_score':scores[i]})\n",
    "                  for i in range(len(queries))]\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def local_prune(self, queries: List[Query]) -> List[PruneResponse]:\n",
    "        query_groups = defaultdict(list)\n",
    "        idx_groups = defaultdict(list)\n",
    "        \n",
    "        outputs = [None for i in queries]\n",
    "        \n",
    "        for i, query in enumerate(queries):\n",
    "            collection_index = query.data['_internal'].get('collection_index', -1)\n",
    "            query_groups[collection_index].append(query)\n",
    "            idx_groups[collection_index].append(i)\n",
    "            \n",
    "        for collection_idx, query_list in query_groups.items():\n",
    "            prune_results = self.prune_queries(query_list)\n",
    "            scatter_idxs = idx_groups[collection_idx]\n",
    "            \n",
    "            for i, result in enumerate(prune_results):\n",
    "                outputs[scatter_idxs[i]] = result\n",
    "                \n",
    "        return outputs\n",
    "    \n",
    "    def __call__(self, queries: List[Query]) -> List[PruneResponse]:\n",
    "        if self.local:\n",
    "            outputs = self.local_prune(queries)\n",
    "        else:\n",
    "            outputs = self.prune_queries(queries)\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = Query(embedding=[0.1])\n",
    "q1.add_collection_index(0)\n",
    "q1.add_query_results([\n",
    "    Item(embedding=[0.11], score=-10),\n",
    "    Item(embedding=[0.12], score=6),\n",
    "])\n",
    "\n",
    "q2 = Query(embedding=[0.2])\n",
    "q2.add_collection_index(0)\n",
    "q2.add_query_results([\n",
    "    Item(embedding=[0.21], score=4),\n",
    "    Item(embedding=[0.22], score=5),\n",
    "])\n",
    "\n",
    "q3 = Query(embedding=[0.3])\n",
    "q3.add_collection_index(1)\n",
    "q3.add_query_results([\n",
    "    Item(embedding=[0.31], score=7),\n",
    "    Item(embedding=[0.32], score=8),\n",
    "])\n",
    "\n",
    "queries = [q1, q2, q3]\n",
    "\n",
    "prune_func = TopKPrune(k=1, agg='max', local=True)\n",
    "\n",
    "assert [i.valid for i in prune_func(queries)] == [True, False, True]\n",
    "\n",
    "prune_func = TopKPrune(k=1, agg='mean', local=True)\n",
    "\n",
    "assert [i.valid for i in prune_func(queries)] == [False, True, True]\n",
    "\n",
    "prune_func = TopKPrune(k=1, agg='mean', local=False)\n",
    "\n",
    "assert [i.valid for i in prune_func(queries)] == [False, False, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emb_opt",
   "language": "python",
   "name": "emb_opt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
