{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> core functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmai/miniconda3/envs/emb_opt/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from emb_opt.imports import *\n",
    "from emb_opt.utils import batch_list, unbatch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Executor():\n",
    "    def __init__(self, \n",
    "                 batched: bool,\n",
    "                 batch_size: int=1\n",
    "                ):\n",
    "        self.batched = batched\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def batch_inputs(self, executor_inputs):\n",
    "        if self.batched:\n",
    "            executor_inputs = batch_list(executor_inputs, self.batch_size)\n",
    "        return executor_inputs\n",
    "            \n",
    "    def unbatch_inputs(self, results):\n",
    "        if self.batched:\n",
    "            results = unbatch_list(results)\n",
    "        return results\n",
    "    \n",
    "    def execute(self, executor_function, executor_inputs):\n",
    "        results = [executor_function(i) for i in executor_inputs]\n",
    "        return results\n",
    "        \n",
    "    def __call__(self, \n",
    "                 executor_function: Callable, \n",
    "                 executor_inputs: BaseModel,\n",
    "                ) -> BaseModel:\n",
    "        \n",
    "        executor_inputs = self.batch_inputs(executor_inputs)\n",
    "        results = self.execute(executor_function, executor_inputs)\n",
    "        results = self.unbatch_inputs(results)\n",
    "            \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class ProcessExecutor(Executor):\n",
    "    def __init__(self,\n",
    "                 batched: bool,\n",
    "                 batch_size: int=1,\n",
    "                 concurrency: Optional[int]=1,\n",
    "                ):\n",
    "        self.batched = batched\n",
    "        self.concurrency = concurrency\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def execute(self, executor_function, executor_inputs):\n",
    "        if (self.concurrency is None) or (self.concurrency==1):\n",
    "            results = [executor_function(i) for i in executor_inputs]\n",
    "        else:\n",
    "            with ProcessPoolExecutor(min(self.concurrency, len(executor_inputs))) as p:\n",
    "                results = list(p.map(executor_function, executor_inputs))\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    def __call__(self, \n",
    "                 executor_function: Callable, \n",
    "                 executor_inputs: BaseModel,\n",
    "                ) -> BaseModel:\n",
    "        \n",
    "        executor_inputs = self.batch_inputs(executor_inputs)\n",
    "        results = self.execute(executor_function, executor_inputs)\n",
    "        results = self.unbatch_inputs(results)\n",
    "            \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class ThreadExecutor(Executor):\n",
    "    def __init__(self,\n",
    "                 batched: bool,\n",
    "                 concurrency: int=1,\n",
    "                 batch_size: int=1,\n",
    "                ):\n",
    "        self.batched = batched\n",
    "        self.concurrency = concurrency\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def execute(self, executor_function, executor_inputs):\n",
    "        if (self.concurrency is None) or (self.concurrency==1):\n",
    "            results = [executor_function(i) for i in executor_inputs]\n",
    "        else:\n",
    "            with ThreadPoolExecutor(min(self.concurrency, len(executor_inputs))) as p:\n",
    "                results = list(p.map(executor_function, executor_inputs))\n",
    "            \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class DatasetExecutor(Executor):\n",
    "    def __init__(self,\n",
    "                 output_schema: BaseModel,\n",
    "                 batched: bool,\n",
    "                 concurrency: Optional[int]=1,\n",
    "                 batch_size: int=1,\n",
    "                 map_kwargs: Optional[dict]=None\n",
    "                ):\n",
    "        self.output_schema = output_schema\n",
    "        self.batched = batched\n",
    "        self.concurrency = concurrency\n",
    "        self.batch_size = batch_size\n",
    "        self.map_kwargs = map_kwargs if map_kwargs else {}\n",
    "        \n",
    "    def execute(self, executor_function, executor_inputs):\n",
    "        \n",
    "        dataset = datasets.Dataset.from_list([i.model_dump() for i in executor_inputs])\n",
    "        dataset = dataset.map(lambda row: executor_function(row), batched=self.batched, \n",
    "                             batch_size=self.batch_size, num_proc=self.concurrency, **self.map_kwargs)\n",
    "        results = [self.output_schema(**i) for i in dataset.to_list()]\n",
    "        return results\n",
    "    \n",
    "    def __call__(self, \n",
    "                 executor_function: Callable, \n",
    "                 executor_inputs: BaseModel\n",
    "                ) -> BaseModel:\n",
    "        results = self.execute(executor_function, executor_inputs)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "class TestInput(BaseModel):\n",
    "    value: float\n",
    "        \n",
    "class TestOutput(BaseModel):\n",
    "    result: bool\n",
    "        \n",
    "def test_function(input: TestInput) -> TestOutput:\n",
    "    return TestOutput(result=input.value>0.5)\n",
    "\n",
    "def test_function_batched(inputs: list[TestInput]) -> list[TestOutput]:\n",
    "    return [TestOutput(result=i.value>0.5) for i in inputs]\n",
    "\n",
    "def test_function_hf(input: dict) -> dict:\n",
    "    return {'result' : input['value']>0.5}\n",
    "\n",
    "def test_function_hf_batched(input: dict) -> dict:\n",
    "    return {'result' : [i>0.5 for i in input['value']]}\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "values = np.random.uniform(size=100).tolist()\n",
    "\n",
    "inputs = [TestInput(value=i) for i in values]\n",
    "expected_outputs = [TestOutput(result=i>0.5) for i in values]\n",
    "\n",
    "# standard\n",
    "\n",
    "executor = Executor(batched=False)\n",
    "res1 = executor(test_function, inputs)\n",
    "assert res1 == expected_outputs\n",
    "\n",
    "executor = Executor(batched=True, batch_size=5)\n",
    "res2 = executor(test_function_batched, inputs)\n",
    "assert res2 == expected_outputs\n",
    "\n",
    "# process\n",
    "\n",
    "executor = ProcessExecutor(batched=False, concurrency=1)\n",
    "res3 = executor(test_function, inputs)\n",
    "assert res3 == expected_outputs\n",
    "\n",
    "executor = ProcessExecutor(batched=False, concurrency=2)\n",
    "res4 = executor(test_function, inputs)\n",
    "assert res4 == expected_outputs\n",
    "\n",
    "executor = ProcessExecutor(batched=True, batch_size=5)\n",
    "res5 = executor(test_function_batched, inputs)\n",
    "assert res5 == expected_outputs\n",
    "\n",
    "executor = ProcessExecutor(batched=True, batch_size=5, concurrency=2)\n",
    "res6 = executor(test_function_batched, inputs)\n",
    "assert res6 == expected_outputs\n",
    "\n",
    "# thread\n",
    "\n",
    "executor = ThreadExecutor(batched=False, concurrency=1)\n",
    "res7 = executor(test_function, inputs)\n",
    "assert res7 == expected_outputs\n",
    "\n",
    "executor = ThreadExecutor(batched=False, concurrency=2)\n",
    "res8 = executor(test_function, inputs)\n",
    "assert res8 == expected_outputs\n",
    "\n",
    "executor = ThreadExecutor(batched=True, batch_size=5)\n",
    "res9 = executor(test_function_batched, inputs)\n",
    "assert res9 == expected_outputs\n",
    "\n",
    "executor = ThreadExecutor(batched=True, batch_size=5, concurrency=2)\n",
    "res10 = executor(test_function_batched, inputs)\n",
    "assert res10 == expected_outputs\n",
    "\n",
    "# dataset\n",
    "\n",
    "executor = DatasetExecutor(TestOutput, batched=False, concurrency=None, batch_size=1)\n",
    "res11 = executor(test_function_hf, inputs)\n",
    "assert res11 == expected_outputs\n",
    "\n",
    "executor = DatasetExecutor(TestOutput, batched=False, concurrency=2, batch_size=1)\n",
    "res12 = executor(test_function_hf, inputs)\n",
    "assert res12 == expected_outputs\n",
    "\n",
    "executor = DatasetExecutor(TestOutput, batched=True, concurrency=2, batch_size=5)\n",
    "res13 = executor(test_function_hf_batched, inputs)\n",
    "assert res13 == expected_outputs\n",
    "\n",
    "executor = DatasetExecutor(TestOutput, batched=True, concurrency=None, batch_size=5)\n",
    "res14 = executor(test_function_hf_batched, inputs)\n",
    "assert res14 == expected_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Plugin():\n",
    "    def __init__(self, function: Callable, executor: Executor):\n",
    "        self.function = function\n",
    "        self.executor = executor\n",
    "        \n",
    "    def gather_inputs(self, inputs: BaseModel) -> BaseModel:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def scatter_results(self, inputs: BaseModel, results: BaseModel) -> BaseModel:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def __call__(self, inputs: BaseModel) -> BaseModel:\n",
    "        \n",
    "        function_inputs = self.gather_inputs(inputs)\n",
    "        results = self.executor(self.function, function_inputs)\n",
    "        outputs = self.scatter_results(inputs, results)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emb_opt",
   "language": "python",
   "name": "emb_opt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
