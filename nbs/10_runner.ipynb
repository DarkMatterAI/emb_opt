{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runner\n",
    "\n",
    "> runner functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from emb_opt.imports import *\n",
    "from emb_opt.schemas import (\n",
    "                                Query, \n",
    "                                Batch,\n",
    "                                DataSourceFunction,\n",
    "                                FilterFunction,\n",
    "                                ScoreFunction,\n",
    "                                PruneFunction,\n",
    "                                UpdateFunction\n",
    "                            )\n",
    "from emb_opt.data_source import DataSourceModule\n",
    "from emb_opt.filter import FilterModule\n",
    "from emb_opt.score import ScoreModule\n",
    "from emb_opt.prune import PruneModule\n",
    "from emb_opt.update import UpdateModule\n",
    "from emb_opt.log import Log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Runner` class holds plugin functions for each step and executes the embedding search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Runner():\n",
    "    def __init__(self,\n",
    "                 data_plugin: DataSourceFunction,          # data source function\n",
    "                 filter_plugin: Optional[FilterFunction],  # optional filter function\n",
    "                 score_plugin: ScoreFunction,              # score function\n",
    "                 prune_plugin: Optional[PruneFunction],    # optional prune function\n",
    "                 update_plugin: UpdateFunction             # update function\n",
    "                ):\n",
    "        self.data_module = DataSourceModule(data_plugin)\n",
    "        self.filter_module = FilterModule(filter_plugin)\n",
    "        self.score_module = ScoreModule(score_plugin)\n",
    "        self.prune_module = PruneModule(prune_plugin)\n",
    "        self.update_module = UpdateModule(update_plugin)\n",
    "        \n",
    "    def prepare_batch(self, batch: Batch, iteration: int):\n",
    "        for query in batch.queries:\n",
    "            query.update_internal(iteration=iteration)\n",
    "\n",
    "            \n",
    "    def step(self, \n",
    "             batch: Batch, \n",
    "             log: Log, \n",
    "             iteration: int, \n",
    "             verbose: bool=True\n",
    "            ) -> Batch:\n",
    "        \n",
    "        self.prepare_batch(batch, iteration)\n",
    "        \n",
    "        batch = self.data_module(batch)\n",
    "        batch = self.filter_module(batch)\n",
    "        batch = self.score_module(batch)\n",
    "        batch = self.prune_module(batch)\n",
    "        \n",
    "        log.add_batch(batch)\n",
    "        self.report_scores(batch, iteration, verbose)\n",
    "        \n",
    "        if len(list(batch.valid_queries()))>0:\n",
    "            batch = self.update_module(batch)\n",
    "        else:\n",
    "            batch = None\n",
    "        return batch\n",
    "        \n",
    "    def search(self, \n",
    "               batch: Batch, \n",
    "               iterations: int, \n",
    "               log: Optional[Log]=None, \n",
    "               verbose: bool=True\n",
    "              ) -> (Batch, Log):\n",
    "        if log is None:\n",
    "            log = Log()\n",
    "            \n",
    "        i_start = len(log.batch_log)\n",
    "            \n",
    "        for i in range(i_start, i_start+iterations):\n",
    "            batch = self.step(batch, log, i, verbose)\n",
    "            if batch is None:\n",
    "                break\n",
    "            \n",
    "        return batch, log\n",
    "            \n",
    "    def report_scores(self, batch: Batch, iteration: int, report: bool):\n",
    "        if report:\n",
    "            mean_scores = [np.array([i.score for i in query.valid_results()]).mean() \n",
    "                      for query in batch.flatten_queries()[1]]\n",
    "            print(iteration, ' '.join([f'{i:.2f}' for i in mean_scores]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emb_opt",
   "language": "python",
   "name": "emb_opt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
