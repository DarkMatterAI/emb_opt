{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Tutorial\n",
    "\n",
    "> Tutorial on advanced updates, pruning and gradient queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The previous tutorial gave an overview of the main abstractions in `emb_opt` for basic hill climbing. This notebook goes over some more advanced query updating strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmai/miniconda3/envs/emb_opt/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from emb_opt.imports import *\n",
    "from emb_opt.schemas import Query, Item, Batch, ScoreResponse, FilterResponse\n",
    "from emb_opt.plugins.huggingface import HugggingfaceDataPlugin\n",
    "from emb_opt.update import RLUpdate\n",
    "from emb_opt.runner import Runner\n",
    "from emb_opt.utils import build_batch_from_embeddings\n",
    "\n",
    "import string\n",
    "from datasets import Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To start, we'll set up the same dataset, filter function and score function from the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(n_vectors: int=10000, size: int=64):\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    vectors = np.random.randn(n_vectors, size)\n",
    "\n",
    "    vector_data = [{\n",
    "                    'index' : i,\n",
    "                    'item' : ''.join(np.random.choice([i for i in string.ascii_lowercase], size=10).tolist()),\n",
    "                    'rand' : np.random.rand(),\n",
    "                    'embedding' : vectors[i]\n",
    "                } for i in range(n_vectors)]\n",
    "\n",
    "    vector_dataset = Dataset.from_list(vector_data)\n",
    "    vector_dataset.add_faiss_index('embedding')\n",
    "    \n",
    "    return vector_dataset\n",
    "\n",
    "def get_data_plugin(dataset: Dataset, k: int=10, distance_cutoff: Optional[float]=None):\n",
    "    data_plugin = HugggingfaceDataPlugin(k=k, \n",
    "                                         dataset=dataset, \n",
    "                                         index_name='embedding', \n",
    "                                         item_key='item', \n",
    "                                         id_key='index', \n",
    "                                         distance_cutoff=distance_cutoff\n",
    "                                        )\n",
    "    return data_plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_embeddings(embeddings: np.ndarray, sigma: float=5.) -> np.ndarray:\n",
    "    target_point = np.ones(embeddings.shape[1])*.75\n",
    "    \n",
    "    distances = np.linalg.norm(embeddings - target_point, axis=1) / np.sqrt(embeddings.shape[1])\n",
    "    \n",
    "    scores = np.exp(-0.5 * (distances/sigma)**2)\n",
    "        \n",
    "    return scores\n",
    "\n",
    "def score_plugin(inputs: List[Item]) -> List[ScoreResponse]:\n",
    "    embeddings = np.array([i.embedding for i in inputs])\n",
    "    scores = score_embeddings(embeddings)    \n",
    "    results = [ScoreResponse(valid=True, score=i, data=None) for i in scores]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_plugin(inputs: List[Item]) -> List[FilterResponse]:\n",
    "    return [FilterResponse(valid=i.data['rand']<0.9, data={'rand':i.data['rand']}) for i in inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_batch(n_queries: int=5, size: int=64):\n",
    "    np.random.seed(40)\n",
    "    initial_queries = np.random.randn(n_queries, size)\n",
    "    input_batch = build_batch_from_embeddings(initial_queries)\n",
    "    return input_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create the dataset and an input batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 10/10 [00:00<00:00, 1100.84it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(n_vectors=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emb_opt.schemas.Batch"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch = get_input_batch()\n",
    "type(input_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emb_opt",
   "language": "python",
   "name": "emb_opt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
