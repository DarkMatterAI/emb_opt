{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score\n",
    "\n",
    "> Score functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmai/miniconda3/envs/emb_opt/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from emb_opt.imports import *\n",
    "from emb_opt.core import Module, Executor\n",
    "from emb_opt.schemas import Item, Query, Batch, ScoreFunction, ScoreResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class ScoreModule(Module):\n",
    "    def __init__(self, function: ScoreFunction):\n",
    "        super().__init__(ScoreResponse, function)\n",
    "        \n",
    "    def gather_inputs(self, batch: Batch) -> (List[Tuple], List[Item]):\n",
    "        idxs, inputs = batch.flatten_query_results()\n",
    "        return (idxs, inputs)\n",
    "    \n",
    "    def scatter_results(self, batch: Batch, idxs: List[Tuple], results: List[ScoreResponse]):\n",
    "        for (q_idx, r_idx), result in zip(idxs, results):\n",
    "            batch_item = batch.get_item(q_idx, r_idx)\n",
    "            batch_item.score = result.score\n",
    "            if result.data:\n",
    "                batch_item.data.update(result.data)\n",
    "                \n",
    "            if not result.valid:\n",
    "                batch_item.data['_internal']['remove'] = True\n",
    "                batch_item.data['_internal']['remove_details'] = 'score response invalid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_batch():\n",
    "    np.random.seed(42)\n",
    "    d_emb = 128\n",
    "    query = Query(embedding=np.random.randn(d_emb))\n",
    "    query_results = [Item(embedding=np.random.randn(d_emb), data={'id':i}) for i in range(100)]\n",
    "    expected_scores = [np.linalg.norm(i.embedding) for i in query_results]\n",
    "    query.add_query_results(query_results)\n",
    "    batch = Batch(queries=[query])\n",
    "    return batch, expected_scores\n",
    "\n",
    "def norm_score(input: Item):\n",
    "    embedding = np.array(input.embedding)\n",
    "    norm = np.linalg.norm(embedding)\n",
    "    return ScoreResponse(valid=True, score=norm, data={'norm':norm})\n",
    "\n",
    "def norm_score_batched(inputs: List[Item]):\n",
    "    embeddings = np.array([i.embedding for i in inputs])\n",
    "    norms = np.linalg.norm(embeddings, axis=-1)\n",
    "    results = [ScoreResponse(valid=True, score=i, data={'norm':i}) for i in norms]\n",
    "    return results\n",
    "\n",
    "def test_score(score_module):\n",
    "    batch, expected_scores = build_batch()\n",
    "    batch = score_module(batch)\n",
    "    scores = [i.score for i in batch[0]]\n",
    "    assert np.allclose(expected_scores, scores)\n",
    "\n",
    "func = Executor(norm_score, batched=False)\n",
    "score_module = ScoreModule(func)\n",
    "test_score(score_module)\n",
    "\n",
    "score_module = ScoreModule(norm_score_batched)\n",
    "test_score(score_module)\n",
    "\n",
    "func = Executor(norm_score_batched, batched=True, batch_size=5)\n",
    "score_module = ScoreModule(func)\n",
    "test_score(score_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emb_opt",
   "language": "python",
   "name": "emb_opt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
