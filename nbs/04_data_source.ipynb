{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Source\n",
    "\n",
    "> Data Source functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmai/miniconda3/envs/emb_opt/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from emb_opt.imports import *\n",
    "from emb_opt.utils import build_batch_from_embeddings\n",
    "from emb_opt.module import Module\n",
    "from emb_opt.schemas import Item, Query, Batch, DataSourceFunction, DataSourceResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class DataSourceModule(Module):\n",
    "    def __init__(self, function: DataSourceFunction):\n",
    "        super().__init__(DataSourceResponse, function)\n",
    "        \n",
    "    def gather_inputs(self, batch: Batch) -> (List[Tuple], List[Query]):\n",
    "        idxs, inputs = batch.flatten_queries()\n",
    "        return (idxs, inputs)\n",
    "    \n",
    "    def scatter_results(self, batch: Batch, idxs: List[Tuple], results: List[DataSourceResponse]):\n",
    "        for (q_idx, r_idx), result in zip(idxs, results):\n",
    "            batch_item = batch.get_item(q_idx, r_idx)\n",
    "            if result.data:\n",
    "                batch_item.data.update(result.data)\n",
    "                \n",
    "            if not result.valid:\n",
    "                batch_item.update_internal(removed=True, removal_reason='invalid query')\n",
    "                \n",
    "            elif len(result.query_results)==0:\n",
    "                batch_item.update_internal(removed=True, removal_reason='query returned no results')\n",
    "                \n",
    "            else:\n",
    "                batch_item.add_query_results(result.query_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_batch():\n",
    "    embeddings = [[0.1], [0.2], [0.3]]\n",
    "    batch = build_batch_from_embeddings(embeddings)\n",
    "    return batch\n",
    "\n",
    "def data_source_test(queries: List[Query]) -> List[DataSourceResponse]:\n",
    "    results = []\n",
    "    for i, query in enumerate(queries):\n",
    "        if i==0:\n",
    "            response = DataSourceResponse(valid=False, data={'test':'test false response'},\n",
    "                                         query_results=[Item.from_minimal(item='', embedding=[0.1])])\n",
    "        elif i==1:\n",
    "            response = DataSourceResponse(valid=True, data={'test':'test empty response'},\n",
    "                                         query_results=[])\n",
    "        elif i==2:\n",
    "            response = DataSourceResponse(valid=True, data={'test':'test normal response'},\n",
    "                                         query_results=[Item.from_minimal(item='1', embedding=[0.1]), \n",
    "                                                       Item.from_minimal(item='2', embedding=[0.2])])\n",
    "        results.append(response)\n",
    "    return results\n",
    "\n",
    "batch = build_batch()\n",
    "data_module = DataSourceModule(data_source_test)\n",
    "batch2 = data_module(batch)\n",
    "assert [i.internal.removed for i in batch2] == [True, True, False]\n",
    "\n",
    "for q in batch2:\n",
    "    for r in q:\n",
    "        assert r.internal.parent_id == q.internal.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class DataSourcePlugin():\n",
    "    def __call__(self, inputs: List[Query]) -> List[DataSourceResponse]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class NumpyDataPlugin(DataSourcePlugin):\n",
    "    def __init__(self,\n",
    "                 k: int,\n",
    "                 item_embeddings: np.ndarray,\n",
    "                 item_list: Optional[List[str]]=None,\n",
    "                 item_data: Optional[List[Dict]]=None,\n",
    "                 distance_metric: str='euclidean'\n",
    "                ):\n",
    "        \n",
    "        self.k = k\n",
    "        self.item_embeddings = item_embeddings\n",
    "        self.item_list = item_list\n",
    "        self.item_data = item_data\n",
    "        self.distance_metric = distance_metric\n",
    "        \n",
    "    def __call__(self, inputs: List[Query]) -> List[DataSourceResponse]:\n",
    "        \n",
    "        queries = np.array([i.embedding for i in inputs])\n",
    "        distances = cdist(queries, self.item_embeddings, metric=self.distance_metric)\n",
    "        topk = distances.argsort(-1)[:, :self.k]\n",
    "        \n",
    "        outputs = []\n",
    "        for i in range(len(inputs)):\n",
    "            items = []\n",
    "            query_data = {'query_distance' : []}\n",
    "            for j in topk[i]:\n",
    "                query_data['query_distance'].append(distances[i,j])\n",
    "                \n",
    "                data = dict(self.item_data[j]) if self.item_data else {}\n",
    "                item_value = self.item_list[j] if self.item_list else None\n",
    "                \n",
    "                item = Item(embedding=self.item_embeddings[j], data=data, score=None, item=item_value)\n",
    "                items.append(item)\n",
    "                \n",
    "            result = DataSourceResponse(valid=True, data=query_data, query_results=items)\n",
    "            outputs.append(result)\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vectors = 256\n",
    "d_vectors = 64\n",
    "k = 10\n",
    "n_queries = 5\n",
    "\n",
    "vectors = np.random.randn(n_vectors, d_vectors)\n",
    "vector_data = [{'index':np.random.randint(0,1e6)} for i in range(vectors.shape[0])]\n",
    "item_values = [str(i['index']) for i in vector_data]\n",
    "\n",
    "data_function = NumpyDataPlugin(k, vectors, item_values, vector_data, distance_metric='cosine')\n",
    "data_module = DataSourceModule(data_function)\n",
    "\n",
    "batch = build_batch_from_embeddings(np.random.randn(n_queries, d_vectors))\n",
    "batch2 = data_module(batch)\n",
    "\n",
    "for q in batch2:\n",
    "    for r in q:\n",
    "        assert r.internal.parent_id == q.internal.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class HugggingfaceDataPlugin(DataSourcePlugin):\n",
    "    def __init__(self,\n",
    "                 k: int,\n",
    "                 dataset: datasets.Dataset,\n",
    "                 index_name: str,\n",
    "                 item_name: Optional[str]=None\n",
    "                ):\n",
    "        \n",
    "        self.k = k\n",
    "        self.dataset = dataset\n",
    "        self.index_name = index_name\n",
    "        self.index = self.dataset.get_index(index_name)\n",
    "        self.item_name = item_name\n",
    "        \n",
    "    def __call__(self, inputs: List[Query]) -> List[DataSourceResponse]:\n",
    "        queries = np.array([i.embedding for i in inputs])\n",
    "        \n",
    "        res = self.index.search_batch(queries, k=self.k)\n",
    "        distances = res.total_scores\n",
    "        indices = res.total_indices\n",
    "        \n",
    "        outputs = []\n",
    "        for i in range(indices.shape[0]):\n",
    "            items = []\n",
    "            query_data = {'query_distance' : []}\n",
    "            for j in range(indices.shape[1]):\n",
    "                query_data['query_distance'].append(distances[i,j])\n",
    "                \n",
    "                dataset_index = indices[i, j]\n",
    "                item_data = dict(self.dataset[int(dataset_index)])\n",
    "                embedding = item_data.pop(self.index_name)\n",
    "                item = item_data.pop(self.item_name) if self.item_name else None\n",
    "                \n",
    "                item = Item(embedding=embedding, data=item_data, item=item, score=None)\n",
    "                items.append(item)\n",
    "                \n",
    "            result = DataSourceResponse(valid=True, data=query_data, query_results=items)\n",
    "            outputs.append(result)\n",
    "            \n",
    "        return outputs       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 1957.21it/s]\n"
     ]
    }
   ],
   "source": [
    "n_vectors = 256\n",
    "d_vectors = 64\n",
    "k = 10\n",
    "n_queries = 5\n",
    "\n",
    "vectors = np.random.randn(n_vectors, d_vectors)\n",
    "vector_data = [{'index':np.random.randint(0,1e6), 'embedding':vectors[i]} \n",
    "               for i in range(vectors.shape[0])]\n",
    "\n",
    "dataset = Dataset.from_list(vector_data)\n",
    "dataset.add_faiss_index('embedding')\n",
    "\n",
    "data_function = HugggingfaceDataPlugin(k, dataset, 'embedding', 'index')\n",
    "data_module = DataSourceModule(data_function)\n",
    "\n",
    "batch = build_batch_from_embeddings(np.random.randn(n_queries, d_vectors))\n",
    "batch2 = data_module(batch)\n",
    "\n",
    "for q in batch2:\n",
    "    for r in q:\n",
    "        assert r.internal.parent_id == q.internal.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emb_opt",
   "language": "python",
   "name": "emb_opt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
