{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Source\n",
    "\n",
    "> Data Source functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmai/miniconda3/envs/emb_opt/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from emb_opt.imports import *\n",
    "from emb_opt.utils import build_batch_from_embeddings\n",
    "from emb_opt.module import Module\n",
    "from emb_opt.schemas import Item, Query, Batch, DataSourceFunction, DataSourceResponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data Source step runs a set of queries against some data source.\n",
    "\n",
    "The query is defined by the `DataSourceFunction` schema, which maps inputs `List[Query]` to outputs `List[DataSourceResponse]`.\n",
    "\n",
    "The `DataSourceModule` manages execution of a `DataSourceFunction`. The `DataSourceModule` gathers valid queries, sends them to the `DataSourceFunction`, and processes the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class DataSourceModule(Module):\n",
    "    def __init__(self, \n",
    "                 function: DataSourceFunction # data function\n",
    "                ):\n",
    "        super().__init__(DataSourceResponse, function)\n",
    "        \n",
    "    def gather_inputs(self, batch: Batch) -> (List[Tuple], List[Query]):\n",
    "        idxs, inputs = batch.flatten_queries()\n",
    "        return (idxs, inputs)\n",
    "    \n",
    "    def scatter_results(self, batch: Batch, idxs: List[Tuple], results: List[DataSourceResponse]):\n",
    "        for (q_idx, r_idx), result in zip(idxs, results):\n",
    "            batch_item = batch.get_item(q_idx, r_idx)\n",
    "            if result.data:\n",
    "                batch_item.data.update(result.data)\n",
    "                \n",
    "            if not result.valid:\n",
    "                batch_item.update_internal(removed=True, removal_reason='invalid query')\n",
    "                \n",
    "            elif len(result.query_results)==0:\n",
    "                batch_item.update_internal(removed=True, removal_reason='query returned no results')\n",
    "                \n",
    "            else:\n",
    "                batch_item.add_query_results(result.query_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_batch():\n",
    "    embeddings = [[0.1], [0.2], [0.3]]\n",
    "    batch = build_batch_from_embeddings(embeddings)\n",
    "    return batch\n",
    "\n",
    "def data_source_test(queries: List[Query]) -> List[DataSourceResponse]:\n",
    "    results = []\n",
    "    for i, query in enumerate(queries):\n",
    "        if i==0:\n",
    "            response = DataSourceResponse(valid=False, data={'test':'test false response'},\n",
    "                                         query_results=[Item.from_minimal(item='', embedding=[0.1])])\n",
    "        elif i==1:\n",
    "            response = DataSourceResponse(valid=True, data={'test':'test empty response'},\n",
    "                                         query_results=[])\n",
    "        elif i==2:\n",
    "            response = DataSourceResponse(valid=True, data={'test':'test normal response'},\n",
    "                                         query_results=[Item.from_minimal(item='1', embedding=[0.1]), \n",
    "                                                       Item.from_minimal(item='2', embedding=[0.2])])\n",
    "        results.append(response)\n",
    "    return results\n",
    "\n",
    "batch = build_batch()\n",
    "data_module = DataSourceModule(data_source_test)\n",
    "batch2 = data_module(batch)\n",
    "assert [i.internal.removed for i in batch2] == [True, True, False]\n",
    "\n",
    "for q in batch2:\n",
    "    for r in q:\n",
    "        assert r.internal.parent_id == q.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given pydantic data parsing, the function can also return a json response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_test(queries: List[Query]) -> List[Dict]:\n",
    "    results = [\n",
    "        {\n",
    "            'valid' : True,\n",
    "            'data' : {},\n",
    "            'query_results' : [\n",
    "                {\n",
    "                    'id' : None,\n",
    "                    'item' : 'test',\n",
    "                    'embedding' : [0.1],\n",
    "                    'score' : None,\n",
    "                    'data' : None\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        for i in queries\n",
    "    ]\n",
    "    return results\n",
    "\n",
    "batch = build_batch()\n",
    "data_module = DataSourceModule(json_test)\n",
    "batch2 = data_module(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class DataSourcePlugin():\n",
    "    '''\n",
    "    DataSourcePlugin - documentation for plugin functions to `DataSourceFunction`\n",
    "    \n",
    "    A valid `DataSourceFunction` is any function that maps `List[Query]` to \n",
    "    `List[DataSourceResponse]`. The inputs will be given as `Query` objects. \n",
    "    The outputs can be either a list of `DataSourceResponse` objects or a list of \n",
    "    valid json dictionaries that match the `DataSourceResponse` schema\n",
    "    \n",
    "    Query schema:\n",
    "    \n",
    "    `{\n",
    "        'item' : Optional[Any],\n",
    "        'embedding' : List[float],\n",
    "        'data' : Optional[Dict],\n",
    "        'query_results': [] # will be empty at this stage\n",
    "    }`\n",
    "    \n",
    "    Item schema:\n",
    "    \n",
    "    `{\n",
    "        'id' : Optional[Union[str, int]]\n",
    "        'item' : Optional[Any],\n",
    "        'embedding' : List[float],\n",
    "        'score' : None, # will be None at this stage\n",
    "        'data' : Optional[Dict],\n",
    "    }`\n",
    "    \n",
    "    Input schema:\n",
    "    \n",
    "    `List[Query]`\n",
    "    \n",
    "    DataSourceResponse schema:\n",
    "    \n",
    "    `{\n",
    "        'valid' : bool,\n",
    "        'data' : Optional[Dict],\n",
    "        'query_results' : List[Item]\n",
    "    }`\n",
    "    \n",
    "    Output schema:\n",
    "    \n",
    "    `List[DataSourceResponse]`\n",
    "    \n",
    "    '''\n",
    "    def __call__(self, inputs: List[Query]) -> List[DataSourceResponse]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `NumpyDataPlugin` data source works with any numpy array of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class NumpyDataPlugin(DataSourcePlugin):\n",
    "    '''\n",
    "    NumpyDataPlugin - data plugin for working with numpy arrays. The \n",
    "    data query will run `k` nearest neighbors of the query embeddings \n",
    "    against the `item_embeddings` using `distance_metric`\n",
    "    \n",
    "    Optionally, `item_data` can be provided as a list of dicts, where \n",
    "    `item_data[i]` corresponds to the data for `item_embeddings[i]`.\n",
    "    \n",
    "    If `item_data` is provided, `item_data[i]['id_key']` defines \n",
    "    the ID of item `i`, and `item_data[i]['item_key']` defines the \n",
    "    specific item `i`\n",
    "    \n",
    "    `distance_metric` is any valid scipy distance metric. see \n",
    "    https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 k: int,                               # k nearest neighbors to return\n",
    "                 item_embeddings: np.ndarray,          # item embeddings\n",
    "                 item_data: Optional[List[Dict]]=None, # Optional dict of item data\n",
    "                 id_key: Optional[str]=None,           # Optional key for item id (should be in `item_data` dict)\n",
    "                 item_key: Optional[str]=None,         # Optional key for item value (should be in `item_data` dict)\n",
    "                 distance_metric: str='euclidean'      # distance metric, see options at https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html\n",
    "                ):\n",
    "        \n",
    "        self.k = k\n",
    "        self.item_embeddings = item_embeddings\n",
    "        self.item_data = item_data\n",
    "        self.id_key = id_key\n",
    "        self.item_key = item_key\n",
    "        self.distance_metric = distance_metric\n",
    "        \n",
    "    def __call__(self, inputs: List[Query]) -> List[DataSourceResponse]:\n",
    "        \n",
    "        queries = np.array([i.embedding for i in inputs])\n",
    "        distances = cdist(queries, self.item_embeddings, metric=self.distance_metric)\n",
    "        topk = distances.argsort(-1)[:, :self.k]\n",
    "        \n",
    "        outputs = []\n",
    "        for i in range(len(inputs)):\n",
    "            items = []\n",
    "            query_data = {'query_distance' : []}\n",
    "            for j in topk[i]:\n",
    "                query_data['query_distance'].append(distances[i,j])\n",
    "                \n",
    "                data = None\n",
    "                item_value = None\n",
    "                item_id = None\n",
    "                \n",
    "                if self.item_data:\n",
    "                    data = dict(self.item_data[j])\n",
    "                    if self.id_key:\n",
    "                        item_id = data.pop(self.id_key)\n",
    "                        \n",
    "                    if self.item_key:\n",
    "                        item_value = data.pop(self.item_key)\n",
    "                                \n",
    "                item = Item(id=item_id, \n",
    "                            item=item_value,\n",
    "                            embedding=self.item_embeddings[j], \n",
    "                            data=data, \n",
    "                            score=None)\n",
    "                items.append(item)\n",
    "                \n",
    "            result = DataSourceResponse(valid=True, data=query_data, query_results=items)\n",
    "            outputs.append(result)\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vectors = 256\n",
    "d_vectors = 64\n",
    "k = 10\n",
    "n_queries = 5\n",
    "\n",
    "vectors = np.random.randn(n_vectors, d_vectors)\n",
    "vector_data = [{'index':str(np.random.randint(0,1e6)), \n",
    "                'other':np.random.randint(0,1e3), \n",
    "                'item':str(np.random.randint(0,1e4))} \n",
    "               for i in range(vectors.shape[0])]\n",
    "\n",
    "data_function = NumpyDataPlugin(k, vectors, vector_data, id_key='index', item_key='item', distance_metric='cosine')\n",
    "data_module = DataSourceModule(data_function)\n",
    "\n",
    "batch = build_batch_from_embeddings(np.random.randn(n_queries, d_vectors))\n",
    "batch2 = data_module(batch)\n",
    "\n",
    "for q in batch2:\n",
    "    for r in q:\n",
    "        assert r.internal.parent_id == q.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emb_opt",
   "language": "python",
   "name": "emb_opt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
